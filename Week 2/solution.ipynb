{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "147da55e",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7e53d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import gensim.downloader as api\n",
    "import nltk\n",
    "import contractions\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "697b4e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Word2Vec model...\n",
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Word2Vec model...\")\n",
    "w2v_model = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4a5da83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, w2v_model):\n",
    "    tokens = [word for word in word_tokenize(text.lower()) if word.isalpha()]\n",
    "    vectors = [w2v_model[word] for word in tokens if word in w2v_model]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(w2v_model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5771b2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   v1                                                 v2\n",
       "0   0  Go until jurong point, crazy.. Available only ...\n",
       "1   0                      Ok lar... Joking wif u oni...\n",
       "2   1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   0  U dun say so early hor... U c already then say...\n",
       "4   0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"spam_dataset.csv\", encoding='latin-1')\n",
    "df.drop(columns=['Unnamed: 2','Unnamed: 3','Unnamed: 4'],inplace=True)\n",
    "df['v1'] = df['v1'].map({'ham': 0, 'spam': 1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4867b735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5057</th>\n",
       "      <td>0</td>\n",
       "      <td>Geeeee ... Your internet is really bad today, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5438</th>\n",
       "      <td>0</td>\n",
       "      <td>\\What are youdoing later? Sar xxx\\\"\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5059</th>\n",
       "      <td>0</td>\n",
       "      <td>I think i am disturbing her da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4614</th>\n",
       "      <td>1</td>\n",
       "      <td>Sunshine Quiz! Win a super Sony DVD recorder i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok i msg u b4 i leave my house.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "5057      0  Geeeee ... Your internet is really bad today, ...\n",
       "5438      0               \\What are youdoing later? Sar xxx\\\"\"\n",
       "5059      0                     I think i am disturbing her da\n",
       "4614      1  Sunshine Quiz! Win a super Sony DVD recorder i...\n",
       "798       0                    Ok i msg u b4 i leave my house."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns={'v1':'label','v2':'text'},inplace=True)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58c5dc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\abhis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "def transform_text(text):\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token.isalnum()]\n",
    "    tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
    "    stemmed_tokens = [ps.stem(token) for token in tokens]\n",
    "    \n",
    "    return \" \".join(stemmed_tokens)\n",
    "\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "193b42db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi zeeshan ahmad love work machin learn project studi ml'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_text(\"Hi, I am Zeeshan Ahmad. I love working on Machine Learning projects and studying ML.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4588c6a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>transformed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5155</th>\n",
       "      <td>0</td>\n",
       "      <td>MY NEW YEARS EVE WAS OK. I WENT TO A PARTY WIT...</td>\n",
       "      <td>new year eve went parti boyfriend si hey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>0</td>\n",
       "      <td>Yar lor he wan 2 go c horse racing today mah, ...</td>\n",
       "      <td>yar lor wan 2 go c hors race today mah eat ear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>0</td>\n",
       "      <td>Hi da:)how is the todays class?</td>\n",
       "      <td>hi da today class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3425</th>\n",
       "      <td>0</td>\n",
       "      <td>Sure but since my parents will be working on T...</td>\n",
       "      <td>sure sinc parent work tuesday realli need cove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3133</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok going to sleep. Hope i can meet her.</td>\n",
       "      <td>ok go sleep hope meet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  \\\n",
       "5155      0  MY NEW YEARS EVE WAS OK. I WENT TO A PARTY WIT...   \n",
       "970       0  Yar lor he wan 2 go c horse racing today mah, ...   \n",
       "326       0                    Hi da:)how is the todays class?   \n",
       "3425      0  Sure but since my parents will be working on T...   \n",
       "3133      0            Ok going to sleep. Hope i can meet her.   \n",
       "\n",
       "                                       transformed_text  \n",
       "5155           new year eve went parti boyfriend si hey  \n",
       "970   yar lor wan 2 go c hors race today mah eat ear...  \n",
       "326                                   hi da today class  \n",
       "3425  sure sinc parent work tuesday realli need cove...  \n",
       "3133                              ok go sleep hope meet  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['transformed_text']=df['text'].apply(transform_text)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "81647757",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack(df['transformed_text'].apply(lambda x: vectorize_text(x, w2v_model)))\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d1b6e4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9016a801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9381165919282511\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy:\", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "64003b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_message_class(model, w2v_model, message):\n",
    "    vec = vectorize_text(message, w2v_model).reshape(1, -1)\n",
    "    predicted = model.predict(vec)[0]\n",
    "    if predicted==0:\n",
    "        return \"ham\"\n",
    "    return \"spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "becdc7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_message_class(model, w2v_model, message=\"Nah I don't think he goes to usf, he lives around here though\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a58491",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0266549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"Tweets_dataset.csv\")\n",
    "df2 = df2[['airline_sentiment', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e82e6a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_tweet(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r\"http\\S+|www\\S+|@\\S+|#\\S+\", \"\", tweet)\n",
    "    tweet = re.sub(r\"[^\\w\\s]\", \"\", tweet)\n",
    "    tweet = contractions.fix(tweet)\n",
    "    tokens = word_tokenize(tweet)\n",
    "    return ' '.join([lemmatizer.lemmatize(w) for w in tokens if w not in stopwords.words('english') and w.isalpha()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e19bc583",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Processed'] = df2['text'].apply(preprocess_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "875bc4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = np.vstack(df2['Processed'].apply(lambda x: vectorize_text(x, w2v_model)))\n",
    "y2 = df2['airline_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c63b688e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "611863bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7711748633879781\n"
     ]
    }
   ],
   "source": [
    "model2 = LogisticRegression(max_iter=1000)\n",
    "model2.fit(X2_train, y2_train)\n",
    "print(\"Accuracy:\", model2.score(X2_test, y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0927f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tweet_sentiment(model, w2v_model, tweet):\n",
    "    vec = vectorize_text(tweet, w2v_model).reshape(1, -1)\n",
    "    return model.predict(vec)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774708fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
